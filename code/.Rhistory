ate = est.ri.ate(regr_table,regr_table$treatment)
all_ate <- replicate(5000, est.ri.ate(regr_table, rand_ass()))
# two-tailed p-val, is this correct?
mean(ate < all_ate & -ate > -all_ate)
n10 = nrow(worker_perf_0.10)
n25 = nrow(worker_perf_0.25)
n40 = nrow(worker_perf_0.40)
n55 = nrow(worker_perf_0.55)
rand_ass = function() sample(c(rep(0.1,n10),rep(0.25,n25), rep(0.4,n40), rep(0.55,n55)))
# treatment = rand_ass()
ate = est.ri.ate(regr_table,regr_table$treatment)
all_ate <- replicate(5000, est.ri.ate(regr_table, rand_ass()))
# two-tailed p-val, is this correct?
mean(ate < all_ate & -ate > -all_ate)
worker_perf_0.25
# Use this code to evaluate worker performance based on pilot resul csvs
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# NOTES FROM PROBLEM SHEETS AND ANY CAVEATS?
## Combining experiments:  See PS2, problem 2, part d, about pooling data from two different studies that have very different means and std errors.
##  This causes biased results if the data is just pooled. we should use Equation 3.10 in FE Ch.3, this is the right way.
## Discuss confidence intervals
## Do we need to worry about clustering in this case? I guess our experiments aren't separate clusters as we are getting samples from the same population (roughly)
##  probably a good idea to briefly discuss this in our final report.
## Blocking? I guess we don't have it...
## Formulate results from all regressions in nice tables, like the ones seen in readings.
## Dimensions of our experiment? Also, we should probably create those cool simple regression models with the X's Os and Ts
## Do we have Compliers and Never-takers? Are they enough to make a difference?
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.10
# read in qualtric output csv
qualtric_data_path_0.10 = "../qualtric_data/20171111_qualtric_results_order1_0.10.csv"
current_task_data_0.10 = get_current_task_data(qualtric_data_path_0.10)
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.10 = evaluate_question_perf(current_task_data_0.10, allQ)
question_perf_0.10
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.10, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.10 = evaluate_worker_perf(current_task_data_0.10, allQ)
worker_perf_0.10
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.10, allQ)
#number of observations valid for regression
nrow(worker_perf_0.10)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.55
# read in qualtric output csv
qualtric_data_path_0.55 = "../qualtric_data/20171111_qualtric_results_order1_0.55.csv"
current_task_data_0.55 = get_current_task_data(qualtric_data_path_0.55)
# !!! REMOVE REPEATERS : turks who checked out the 0.10 task already
filter = !(current_task_data_0.55$worker_id %in% current_task_data_0.10$worker_id)
# get number of violaters
sum_spillover = sum(!filter)
# weed out the violaters
current_task_data_0.55_weeded = current_task_data_0.55[filter, ]
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.55 = evaluate_question_perf(current_task_data_0.55_weeded, allQ)
question_perf_0.55
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.55_weeded, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.55 = evaluate_worker_perf(current_task_data_0.55_weeded, allQ)
worker_perf_0.55
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.55_weeded, allQ)
#number of observations valid for regression
nrow(worker_perf_0.55)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.40
# Please fill in (reuse above code block)
# read in qualtric output csv
qualtric_data_path_0.40 = "../qualtric_data/20171112_qualtric_results_order1_0.40.csv"
current_task_data_0.40 = get_current_task_data(qualtric_data_path_0.40)
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.40 = evaluate_question_perf(current_task_data_0.40, allQ)
question_perf_0.40
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.40, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.40 = evaluate_worker_perf(current_task_data_0.40, allQ)
worker_perf_0.40
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.40, allQ)
#number of observations valid for regression
nrow(worker_perf_0.40)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.25
# Please fill in (reuse above code block)
# read in qualtric output csv
qualtric_data_path_0.25 = "../qualtric_data/20171112_qualtric_results_order1_0.25.csv"
current_task_data_0.25 = get_current_task_data(qualtric_data_path_0.25)
# !!! REMOVE REPEATERS : turks who checked out the 0.40 task already
filter = !(current_task_data_0.25$worker_id %in% current_task_data_0.40$worker_id)
# get number of violaters
sum_spillover = sum(!filter)
# weed out the violaters
current_task_data_0.25_weeded = current_task_data_0.25[filter, ]
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.25 = evaluate_question_perf(current_task_data_0.25_weeded, allQ)
question_perf_0.25
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.25_weeded, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.25 = evaluate_worker_perf(current_task_data_0.25_weeded, allQ)
worker_perf_0.25
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.25_weeded, allQ)
#number of observations valid for regression
nrow(worker_perf_0.25)
#---------------------------------------------------------------------#
# POOLING TWO CSV FILES FROM DIFFERENT TREATMENTS
# pool the data from different treatments together
worker_perf_0.10$treatment = 0.10
worker_perf_0.55$treatment = 0.55
worker_perf_0.40$treatment = 0.40
worker_perf_0.25$treatment = 0.25
regr_table = rbind(worker_perf_0.10, worker_perf_0.25, worker_perf_0.40, worker_perf_0.55) # ONCE ALL FOUR POSTINGS ARE DONE
# our covariates are CQ1, CQ2_3, CQ3
# converting some data type of some covariates
regr_table$CQ1 = as.factor(regr_table$CQ1)
regr_table$CQ2_3 = as.numeric(regr_table$CQ2_3)
regr_table$CQ3 = as.factor(regr_table$CQ3)
# converting data types for Q4 and Q5 if we decide to use it
# remember that these are bad controls in Design1, never regress on them
# on the other hand, they are OK in Design2, can regress on then
regr_table$CQ5 = regr_table$CQ5 == "Yes"
regr_table$CQ4 = as.factor(regr_table$CQ4)
#---------------------------------------------------------------------#
# CHECK COVARIATE BALANCE
# Dog friends question
CQ1_1 = regr_table$CQ1 == "a lot less than half"
CQ1_2 = regr_table$CQ1 == "around half"
CQ1_3 = regr_table$CQ1 == "a lot more than half"
cov_regr_CQ1_1= lm(CQ1_1 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ1_1, vcov(cov_regr_CQ1_1))
cov_regr_CQ1_2= lm(CQ1_2 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ1_2, vcov(cov_regr_CQ1_2))
cov_regr_CQ1_3= lm(CQ1_3 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ1_3, vcov(cov_regr_CQ1_3))
# Preference to work with images question
cov_regr_CQ2_3= lm(CQ2_3 ~ treatment, data = regr_table)
lmtest::coeftest(cov_regr_CQ2_3, vcov(cov_regr_CQ2_3))
# Lived with or planned to own a dog
CQ3_1 = regr_table$CQ3 == "Yes"
CQ3_2 = regr_table$CQ3 == "No"
CQ3_3 = regr_table$CQ3 == "Maybe"
cov_regr_CQ3_1= lm(CQ3_1 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ3_1, vcov(cov_regr_CQ3_1))
cov_regr_CQ3_2= lm(CQ3_2 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ3_2, vcov(cov_regr_CQ3_2))
cov_regr_CQ3_3= lm(CQ3_3 ~ regr_table$treatment)
lmtest::coeftest(cov_regr_CQ3_3, vcov(cov_regr_CQ3_3))
#---------------------------------------------------------------------#
# ESTIMATING ATE
# ATE by T-test
est.t.test(worker_perf_0.10$accuracy,worker_perf_0.55$accuracy, "two.sided")
est.t.test(worker_perf_0.10$accuracy,worker_perf_0.25$accuracy, "two.sided")
est.t.test(worker_perf_0.10$accuracy,worker_perf_0.40$accuracy, "two.sided")
est.t.test(worker_perf_0.25$accuracy,worker_perf_0.40$accuracy, "two.sided")
est.t.test(worker_perf_0.25$accuracy,worker_perf_0.55$accuracy, "two.sided")
est.t.test(worker_perf_0.40$accuracy,worker_perf_0.55$accuracy, "two.sided")
# ATE by REGRESSION
# REMEMBER TO REPORT
# -COEFFICIENT INTERPRETATION
# -STANDARD ERRORS
# -CONFIDENCE INTERVAL
# -F-TEST on the 3 covariates as a block (restricted only has treatment)(full has CQ1-CQ3 as well)
# ---we want to see if the covariates as a block has any explanatory power
est.regr.simple(regr_table)
est.regr.covars(regr_table)
#---------------------------------------------------------------------#
# RANDOMIZATION INFERENCE
n10 = nrow(worker_perf_0.10)
n25 = nrow(worker_perf_0.25)
n40 = nrow(worker_perf_0.40)
n55 = nrow(worker_perf_0.55)
rand_ass = function() sample(c(rep(0.1,n10),rep(0.25,n25), rep(0.4,n40), rep(0.55,n55)))
# treatment = rand_ass()
ate = est.ri.ate(regr_table,regr_table$treatment)
all_ate <- replicate(5000, est.ri.ate(regr_table, rand_ass()))
mean(ate < all_ate & -ate > -all_ate)
hist(all_ate)
ate
est.regr.simple(regr_table)
est.regr.covars(regr_table)
worker_perf_0.10$treatment = 0.10
worker_perf_0.55$treatment = 0.55
worker_perf_0.40$treatment = 0.40
worker_perf_0.25$treatment = 0.25
regr_table = rbind(worker_perf_0.10, worker_perf_0.25, worker_perf_0.40, worker_perf_0.55) # ONCE ALL FOUR POSTINGS ARE DONE
# our covariates are CQ1, CQ2_3, CQ3
# converting some data type of some covariates
regr_table$CQ1 = as.factor(regr_table$CQ1)
regr_table$CQ2_3 = as.numeric(regr_table$CQ2_3)
regr_table$CQ3 = as.factor(regr_table$CQ3)
# converting data types for Q4 and Q5 if we decide to use it
# remember that these are bad controls in Design1, never regress on them
# on the other hand, they are OK in Design2, can regress on then
regr_table$CQ5 = regr_table$CQ5 == "Yes"
regr_table$CQ4 = as.factor(regr_table$CQ4)
worker_perf_0.25
summarize_worker_perf(current_task_data_0.25_weeded, allQ)
worker_perf_0.40
summarize_worker_perf(current_task_data_0.40, allQ)
summarize_worker_perf(current_task_data_0.40, allQ)
worker_perf_0.25
summarize_worker_perf(current_task_data_0.25_weeded, allQ)
worker_perf_0.55
summarize_worker_perf(current_task_data_0.55_weeded, allQ)
summarize_worker_perf(current_task_data_0.10, allQ)
regr_table
regr_table
regr_table
# our covariates are CQ1, CQ2_3, CQ3
# converting some data type of some covariates
regr_table_exclude0.10$CQ1 = as.factor(regr_table$CQ1)
regr_table_exclude0.10$CQ2_3 = as.numeric(regr_table$CQ2_3)
regr_table_exclude0.10$CQ3 = as.factor(regr_table$CQ3)
regr_table_exclude0.10 = rbind(worker_perf_0.25, worker_perf_0.40, worker_perf_0.55)
# our covariates are CQ1, CQ2_3, CQ3
# converting some data type of some covariates
regr_table_exclude0.10$CQ1 = as.factor(regr_table$CQ1)
regr_table_exclude0.10$CQ2_3 = as.numeric(regr_table$CQ2_3)
regr_table_exclude0.10$CQ3 = as.factor(regr_table$CQ3)
# Use this code to evaluate worker performance based on pilot resul csvs
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# NOTES FROM PROBLEM SHEETS AND ANY CAVEATS?
## Combining experiments:  See PS2, problem 2, part d, about pooling data from two different studies that have very different means and std errors.
##  This causes biased results if the data is just pooled. we should use Equation 3.10 in FE Ch.3, this is the right way.
## Discuss confidence intervals
## Do we need to worry about clustering in this case? I guess our experiments aren't separate clusters as we are getting samples from the same population (roughly)
##  probably a good idea to briefly discuss this in our final report.
## Blocking? I guess we don't have it...
## Formulate results from all regressions in nice tables, like the ones seen in readings.
## Dimensions of our experiment? Also, we should probably create those cool simple regression models with the X's Os and Ts
## Do we have Compliers and Never-takers? Are they enough to make a difference?
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.10
# read in qualtric output csv
qualtric_data_path_0.10 = "../qualtric_data/20171111_qualtric_results_order1_0.10.csv"
current_task_data_0.10 = get_current_task_data(qualtric_data_path_0.10)
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.10 = evaluate_question_perf(current_task_data_0.10, allQ)
question_perf_0.10
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.10, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.10 = evaluate_worker_perf(current_task_data_0.10, allQ)
worker_perf_0.10
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.10, allQ)
#number of observations valid for regression
nrow(worker_perf_0.10)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.55
# read in qualtric output csv
qualtric_data_path_0.55 = "../qualtric_data/20171111_qualtric_results_order1_0.55.csv"
current_task_data_0.55 = get_current_task_data(qualtric_data_path_0.55)
# !!! REMOVE REPEATERS : turks who checked out the 0.10 task already
filter = !(current_task_data_0.55$worker_id %in% current_task_data_0.10$worker_id)
# get number of violaters
sum_spillover = sum(!filter)
# weed out the violaters
current_task_data_0.55_weeded = current_task_data_0.55[filter, ]
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.55 = evaluate_question_perf(current_task_data_0.55_weeded, allQ)
question_perf_0.55
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.55_weeded, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.55 = evaluate_worker_perf(current_task_data_0.55_weeded, allQ)
worker_perf_0.55
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.55_weeded, allQ)
#number of observations valid for regression
nrow(worker_perf_0.55)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.40
# Please fill in (reuse above code block)
# read in qualtric output csv
qualtric_data_path_0.40 = "../qualtric_data/20171112_qualtric_results_order1_0.40.csv"
current_task_data_0.40 = get_current_task_data(qualtric_data_path_0.40)
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.40 = evaluate_question_perf(current_task_data_0.40, allQ)
question_perf_0.40
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.40, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.40 = evaluate_worker_perf(current_task_data_0.40, allQ)
worker_perf_0.40
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.40, allQ)
#number of observations valid for regression
nrow(worker_perf_0.40)
#---------------------------------------------------------------------#
# FOCUS ON A SINGLE CSV FILE CORRESPONDING TO A SINGLE TREATMENT
# ORDER 1, PAYMENT RATE = 0.25
# Please fill in (reuse above code block)
# read in qualtric output csv
qualtric_data_path_0.25 = "../qualtric_data/20171112_qualtric_results_order1_0.25.csv"
current_task_data_0.25 = get_current_task_data(qualtric_data_path_0.25)
# !!! REMOVE REPEATERS : turks who checked out the 0.40 task already
filter = !(current_task_data_0.25$worker_id %in% current_task_data_0.40$worker_id)
# get number of violaters
sum_spillover = sum(!filter)
# weed out the violaters
current_task_data_0.25_weeded = current_task_data_0.25[filter, ]
# evaluate accuracy per question
# of a particular question, how many people got it right?
question_perf_0.25 = evaluate_question_perf(current_task_data_0.25_weeded, allQ)
question_perf_0.25
#stats summary of accuracies over all questions
summarize_question_accuracy(current_task_data_0.25_weeded, allQ)
#evaluate accuracy per worker, return a table per worker
worker_perf_0.25 = evaluate_worker_perf(current_task_data_0.25_weeded, allQ)
worker_perf_0.25
#stats summary of accuracies over all workers
summarize_worker_perf(current_task_data_0.25_weeded, allQ)
#number of observations valid for regression
nrow(worker_perf_0.25)
worker_perf_0.10$treatment = 0.10
worker_perf_0.55$treatment = 0.55
worker_perf_0.40$treatment = 0.40
worker_perf_0.25$treatment = 0.25
regr_table = rbind(worker_perf_0.10, worker_perf_0.25, worker_perf_0.40, worker_perf_0.55) # ONCE ALL FOUR POSTINGS ARE DONE
regr_table$CQ1 = as.factor(regr_table$CQ1)
regr_table$CQ2_3 = as.numeric(regr_table$CQ2_3)
regr_table$CQ3 = as.factor(regr_table$CQ3)
regr_table_exclude0.10 = rbind(worker_perf_0.25, worker_perf_0.40, worker_perf_0.55)
regr_table_exclude0.10$CQ1 = as.factor(regr_table_exclude0.10$CQ1)
regr_table_exclude0.10$CQ2_3 = as.numeric(regr_table_exclude0.10$CQ2_3)
regr_table_exclude0.10$CQ3 = as.factor(regr_table_exclude0.10$CQ3)
est.regr.simple(regr_table)
est.regr.simple(regr_table_exclude0.10)
est.regr.covars(regr_table_exclude0.10)
est.regr.simple(regr_table_exclude0.10)
est.regr.simple(regr_table_exclude0.10) # ATE =
est.regr.simple(regr_table_exclude0.10) # ATE =
est.regr.covars(regr_table_exclude0.10) # ATE =
ate_exclude_0.10 = est.ri.ate(regr_table_exclude0.10,regr_table_exclude0.10$treatment)
all_ate_exclude_0.10 <- replicate(5000, est.ri.ate(regr_table_exclude0.10, rand_ass()))
hist(all_ate_exclude_0.10)
# two-tailed p-val, is this correct?
mean(ate_exclude_0.10 < all_ate_exclude_0.10 & -ate_exclude_0.10 > -all_ate_exclude_0.10)
all_ate_exclude_0.10 <- replicate(5000, est.ri.ate(regr_table_exclude0.10, rand_ass()))
ate_exclude_0.10 = est.ri.ate(regr_table_exclude0.10,regr_table_exclude0.10$treatment)
rand_ass = function() sample(c(rep(0.1,n10),rep(0.25,n25), rep(0.4,n40), rep(0.55,n55)))
all_ate_exclude_0.10 <- replicate(5000, est.ri.ate(regr_table_exclude0.10, rand_ass()))
n10 = nrow(worker_perf_0.10)
n25 = nrow(worker_perf_0.25)
n40 = nrow(worker_perf_0.40)
n55 = nrow(worker_perf_0.55)
rand_ass = function() sample(c(rep(0.1,n10),rep(0.25,n25), rep(0.4,n40), rep(0.55,n55)))
ate_exclude_0.10 = est.ri.ate(regr_table_exclude0.10,regr_table_exclude0.10$treatment)
all_ate_exclude_0.10 <- replicate(5000, est.ri.ate(regr_table_exclude0.10, rand_ass()))
hist(all_ate_exclude_0.10)
# two-tailed p-val, is this correct?
mean(ate_exclude_0.10 < all_ate_exclude_0.10 & -ate_exclude_0.10 > -all_ate_exclude_0.10)
mean(ate_exclude_0.10 < all_ate_exclude_0.10 & -ate_exclude_0.10 > -all_ate_exclude_0.10)
est.regr.simple(regr_table_exclude0.10) # ATE = 0.23
est.regr.simple(regr_table) #ATE = 0.87 result is problematic
est.regr.covars(regr_table_exclude0.10) # ATE = 0.20
est.regr.highord = function(r_table){
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = r_table)
lmtest::coeftest(regr, vcov(regr))
}
est.regr.highord(regr_table)
est.regr.highord(regr_table)
treatment_sq <- regr_table$treatment^2
treatment_cubed <- regr_table$treatment^3
est.regr.highord(regr_table)
plot(allEffects(est.regr.highord, default.levels=50))
library(effects)
plot(allEffects(est.regr.highord, default.levels=50))
est.regr.highord = function(r_table){
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = r_table)
lmtest::coeftest(regr, vcov(regr))
regr
}
est.regr.highord(regr_table)
est.regr.highord = function(r_table){
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = r_table)
print(lmtest::coeftest(regr, vcov(regr)))
regr
}
plot(allEffects(est.regr.highord, default.levels=50))
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = r_table)
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = regr_table)
plot(allEffects(est.regr.highord, default.levels=50))
regr = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = regr_table)
plot(allEffects(regr, default.levels=50))
plot(allEffects(regr, default.levels=50))
library(Hmisc)
library(mcprofile)
library(moments)
library(lmtest)
library(car)
library(sandwich)
library(effects)
library(ggplot2)
library(reshape2)
library(cowplot)
library(MASS)
plot(allEffects(regr, default.levels=50))
dev.off()
plot(allEffects(regr, default.levels=50))
regr.sqord = lm(accuracy ~ treatment + treatment_sq + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.sqord))
# dev.off() --> if the following line gives an error
plot(allEffects(regr.sqord, default.levels=50))
regr.cubedord = lm(accuracy ~ treatment + treatment_sq + treatment_cubed + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.cubedord))
# dev.off() --> if the following line gives an error
plot(allEffects(regr.cubedord, default.levels=50))
regr.sqord = lm(accuracy ~ I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.sqord))
plot(allEffects(regr.sqord, default.levels=50))
plot(allEffects(regr.sqord, default.levels=50))
regr.sqord = lm(accuracy ~ I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.sqord))
regr.sqord = lm(accuracy ~ I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
regr.sqord
regr.sqord = lm(accuracy ~ treament + I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
regr.sqord = lm(accuracy ~ treatment + I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.sqord))
regr.sqord
plot(allEffects(regr.sqord, default.levels=50))
lmtest::coeftest(regr, vcov(regr.sqord))
regr.sqord = lm(accuracy ~ treatment + I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
lmtest::coeftest(regr, vcov(regr.sqord))
plot(allEffects(regr.sqord, default.levels=50))
plot(allEffects(regr.sqord, default.levels=50))
regr.sqord$coefficients
regr.dum = lm(accuracy ~ treatment + CQ1 + CQ2_3 + CQ3, data = regr_table)
regr.dum$coefficients
summary(regr.dum)
summary(regr.sqord)
regr.cubedord = lm(accuracy ~ treatment + I(treatment^2) + I(treatment^3) + CQ1 + CQ2_3 + CQ3, data = regr_table)
summary(regr.cubedord)
lmtest::coeftest(regr, vcov(regr.cubedord)) #the coefficient for "treatment" here is wrong", but SE is correct
plot(allEffects(regr.cubedord, default.levels=50))
regr.sqord = lm(accuracy ~ treatment + I(treatment^2) + CQ1 + CQ2_3 + CQ3, data = regr_table)
summary(regr.sqord)
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in qualtric output csv
dummy_design2_qualtric_data_path = "20171120_qualtric_results_sample_dummy.csv"
dummy_design2_task_data = get_current_task_data(qualtric_data_path_0.40)
dummy_design2_task_data = get_current_task_data(dummy_design2_qualtric_data_path)
dummy_design2_qualtric_data_path = "../qualtric_data/dummy_design2_qualtric_data_path.csv"
dummy_design2_task_data = get_current_task_data(dummy_design2_qualtric_data_path)
lts_sample_dummy.csv"
dummy_design2_task_data = get_current_task_data(dummy_design2_qualtric_data_path)
dummy_design2_task_data
dummy_design2_task_data
get_current_task_data(dummy_design2_qualtric_data_path)
dummy_design2_qualtric_data_path = "../qualtric_data/20171120_qualtric_results_sample_dummy.csv"
dummy_design2_task_data = get_current_task_data(dummy_design2_qualtric_data_path)
dummy_design2_task_data
View(dummy_design2_task_data)
dummy_design2_task_data$LQ1
names(dummy_design2_task_data)
dummy_design2_task_data$LQ1
dummy_design2_task_data$LQ1
dummy_design2_task_data$LQ1
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in qualtric output csv
dummy_design2_qualtric_data_path = "../qualtric_data/20171120_qualtric_results_sample_design2.csv"
dummy_design2_task_data = get_current_task_data(dummy_design2_qualtric_data_path)
View
View(dummy_design2_task_data)
names(dummy_design2_task_data)
dummy_design2_task_data$CCC_SQ1
dummy_design2_task_data[`Timer_CCC_S1_Page Submit`>0,]$CCC_SQ1
dummy_design2_task_data[`Timer_CCC_S1_Page Submit`>0,]
