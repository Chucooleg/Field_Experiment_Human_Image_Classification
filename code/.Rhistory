MTurk_data_path = "../MTurk_data/20171123_mturk_results_design2_pilot.csv" #!!! UPDATE
# load supporting functions
source(file = "design2_data_transformation_functions.r")
#source(file = "design1_data_analysis_functions.r")
existing_path = "../MTurk_ID_status/worker_status.csv"
current_task_data = get_current_task_data(csv_path = qualtric_data_path)
MTurk_worker_id = get_MTurk_worker_id(csv_path = MTurk_data_path)
# adjust the payment threshold if 0.25 task accuracy is too low
worderIDs_task_status = construct_frame_worderIDs_task_status.design2(current_task_data = current_task_data,
submitted_MTurk_ids = MTurk_worker_id,
allQ = allQ.design2,
payment_accuracy_threshold = 0.75,
task_name = "design2 pilot", #!!! UPDATE
treatment_payrate = 0.10, #!!! UPDATE
bonus_rate = 0.05,
existing_path = existing_path)
View(worderIDs_task_status)
worderIDs_task_status$accuracy
worderIDs_task_status$accuracy>0.75
worderIDs_task_status$screener == 1
worderIDs_task_status$complete_task == 1
worderIDs_task_status$repeater == 0
400*0.20*1.5
240*0.20*1.5
240*0.25*1.5
60*0.05
60*0.10
60*0.15
240*0.25*1.5
240*0.20*1.5
60*0.10
60*0.20
60*0.30
72+6+12+18
108*0.70
108*0.75
240*0.22*1.5
79.2 + 6 + 12 + 18
115.2 * 0.8
115.2 * 0.9
108*0.8
240*0.22*1.5
240*0.22*1.5 + 36
115.2*0.8
all.table = fread("design2_OH_simulation.csv")
library(data.table)
all.table = fread("design2_OH_simulation.csv")
View(all.table)
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in qualtric output csv
qualtric_data_path = "../qualtric_data/20171127_qualtric_results_design2_main.csv" #!!! UPDATE
MTurk_data_path = "../MTurk_data/20171127_mturk_results_design2_main.csv" #!!! UPDATE
# load supporting functions
source(file = "design2_data_transformation_functions.r")
existing_path = "../MTurk_ID_status/worker_status.csv"
current_task_data = get_current_task_data(csv_path = qualtric_data_path)
MTurk_worker_id = get_MTurk_worker_id(csv_path = MTurk_data_path)
#---------------------------------------------------------------------#
design2_worker_perf = evaluate_worker_perf.design2(current_task_data, allQ.design2)
View(design2_worker_perf)
stack(design2_worker_perf)
dum = stack(design2_worker_perf)
View(dum)
rm(list = ls())
# Use this code to evaluate worker performance based on pilot resul csvs
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design1_data_transformation_functions.r")
source(file = "design1_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in qualtric output csv
qualtric_data_path = "../qualtric_data/20171127_qualtric_results_design2_main.csv" #!!! UPDATE
MTurk_data_path = "../MTurk_data/20171127_mturk_results_design2_main.csv" #!!! UPDATE
# load supporting functions
source(file = "design2_data_transformation_functions.r")
existing_path = "../MTurk_ID_status/worker_status.csv"
current_task_data = get_current_task_data(csv_path = qualtric_data_path)
MTurk_worker_id = get_MTurk_worker_id(csv_path = MTurk_data_path)
#---------------------------------------------------------------------#
by_HIT.table = evaluate_worker_perf.design2(current_task_data, allQ.design2)
View(by_HIT.table)
stacked = stack(by_HIT.table)
stacked$ind
stacked[stacked$ind == "worker_id", values]
stacked[stacked$ind == "worker_id", "values"]
length(stacked[stacked$ind == "worker_id", "values"])
names(by_HIT.table)
stacked[stacked$ind == "time_spent_S1", "values"]
"CCC"[1]
strsplit("CCC")
strsplit("CCC", split="")
stacked[stacked$ind == "group", "values"]
strsplit(stacked[stacked$ind == "group", "values"], split = "")
strsplit(stacked[stacked$ind == "group", "values"], split = "")[[1]]
strsplit(stacked[stacked$ind == "group", "values"], split = "")[1]
strsplit(stacked[stacked$ind == "group", "values"], split = "")
strsplit(stacked[stacked$ind == "group", "values"], split = "")
stacked[stacked$ind == "group", "values"]
lapply(stacked[stacked$ind == "group", "values"], strsplit(split=""))
?lapply
lapply(stacked[stacked$ind == "group", "values"], strsplit())
lapply(stacked[stacked$ind == "group", "values"], strsplit, split="")
lapply(stacked[stacked$ind == "group", "values"], strsplit, split="")[[1]]
lapply(stacked[stacked$ind == "group", "values"], strsplit, split="")[1]
substr(stacked[stacked$ind == "group", "values"], 1)
substr(stacked[stacked$ind == "group", "values"])
substr(stacked[stacked$ind == "group", "values"], start = 1, end = 2)
substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 2)
substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 1)
substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 1) == "T"
as.numeric(substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 1) == "T")
as.numeric(substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 1) == "T")*0.10
as.numeric(substr(stacked[stacked$ind == "group", "values"], start = 1, stop = 1) == "T")
substr(stacked[stacked$ind == "group", "values"], start = 1)
names(by_HIT.table)
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design2_data_transformation_functions.r")
#source(file = "design2_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in data for analysis
by_HIT.table = fread("../modeling_data/design2_by_HIT.csv")
by_Session.table = fread("../modeling_data/design2_by_Session.csv")
View(by_HIT.table)
View(by_Session.table)
#---------------------------------------------------------------------#
# check attrition
attrition_by_group = lm(observed~group,data=by_HIT.table)
summary(attrition_by_group) #nothing significant
attrition_by_group_CQ1.1 = lm(observed~group,data=by_HIT.table[CQ1=="a lot less than half",])
summary(attrition_by_group_CQ1.1) # groupCCT 0.047434 *
attrition_by_group_CQ1.2 = lm(observed~group,data=by_HIT.table[CQ1=="around half",])
summary(attrition_by_group_CQ1.2) # nothing significant
attrition_by_group_CQ1.3 = lm(observed~group,data=by_HIT.table[CQ1=="a lot more than half",])
summary(attrition_by_group_CQ1.3) # groupCCT 0.00154 *
attrition_by_group_CQ2 = lm(observed~group*CQ2,data=by_HIT.table)
summary(attrition_by_group_CQ2) # nothing significant
attrition_by_group_CQ3.1 = lm(observed~group,data=by_HIT.table[CQ3=="Yes",])
summary(attrition_by_group_CQ3.1) # nothing significant
attrition_by_group_CQ3.2 = lm(observed~group,data=by_HIT.table[CQ3=="No",])
summary(attrition_by_group_CQ3.2) # nothing significant
attrition_by_group_CQ3.3 = lm(observed~group,data=by_HIT.table[CQ3=="Maybe",])
summary(attrition_by_group_CQ3.3) # nothing significant
attrition_by_group_CQ4.1 = lm(observed~group,data=by_HIT.table[CQ4=="0 to 10",])
summary(attrition_by_group_CQ4.1) # nothing significant
attrition_by_group_CQ4.2 = lm(observed~group,data=by_HIT.table[CQ4=="11 to 20",])
summary(attrition_by_group_CQ4.2) # nothing significant
attrition_by_group_CQ4.3 = lm(observed~group,data=by_HIT.table[CQ4=="21 to 30",])
summary(attrition_by_group_CQ4.3) # nothing significant
attrition_by_group_CQ4.4 = lm(observed~group,data=by_HIT.table[CQ4=="31 to 40",])
summary(attrition_by_group_CQ4.4) # nothing significant
attrition_by_group_CQ4.5 = lm(observed~group,data=by_HIT.table[CQ4=="41 or more",])
summary(attrition_by_group_CQ4.5) # nothing significant
attrition_by_group_CQ5.1 = lm(observed~group,data=by_HIT.table[CQ5=="Yes",])
summary(attrition_by_group_CQ5.1) # nothing significant
attrition_by_group_CQ5.2 = lm(observed~group,data=by_HIT.table[CQ5=="No",])
summary(attrition_by_group_CQ5.2) # nothing significant
attrition_by_group_CQ5.3 = lm(observed~group,data=by_HIT.table[CQ5=="Never heard of Linkedin",])
summary(attrition_by_group_CQ5.3) # nothing significant
#---------------------------------------------------------------------#
# check covariate balance (among non-attriters)
# CQ1 "What portion of your friends own pets?"
table(by_HIT.table$CQ1)
cov_check_CQ1.1 = lm(CQ1=="a lot less than half"~group, data=by_HIT.table)
cov_check_CQ1.2 = lm(CQ1=="around half"~group, data=by_HIT.table)
cov_check_CQ1.3 =lm(CQ1=="a lot more than half"~group, data=by_HIT.table)
summary(cov_check_CQ1.1) #nothing significant
summary(cov_check_CQ1.2) #nothing significant
summary(cov_check_CQ1.3) #groupTTT coef has marginally significant p-val 0.0267, meaning Turkers in TTT group are more likely to answer "around half" or "a lot less than half"
# CQ2 "Please rank your preferences to work with the following media:"
# Some numeric rank of "Images"
hist(by_HIT.table$CQ2, breaks = 0:4)
cov_check_CQ2 = lm(CQ2~group, data=by_HIT.table)
summary(cov_check_CQ2) #nothing significant
# CQ3 "Have your ever lived with any dogs in your household? If not, have you ever planned to own a dog?"
cov_check_CQ3.1 = lm(CQ3=="Yes"~group, data=by_HIT.table)
cov_check_CQ3.2 = lm(CQ3=="No"~group, data=by_HIT.table)
cov_check_CQ3.3 = lm(CQ3=="Maybe"~group, data=by_HIT.table)
summary(cov_check_CQ3.1) #nothing significant
summary(cov_check_CQ3.2) #nothing significant
summary(cov_check_CQ3.3) #nothing significant
# CQ4 "On average, how many tasks on Amazon Mechanical Turk do you complete every week?"
# "21 to 30"   "41 or more" "31 to 40"   "11 to 20"   "0 to 10"
cov_check_CQ4.1 = lm(CQ4=="0 to 10"~group, data=by_HIT.table)
cov_check_CQ4.2 = lm(CQ4=="11 to 20"~group, data=by_HIT.table)
cov_check_CQ4.3 = lm(CQ4=="21 to 30"~group, data=by_HIT.table)
cov_check_CQ4.4 = lm(CQ4=="31 to 40"~group, data=by_HIT.table)
cov_check_CQ4.5 = lm(CQ4=="41 or more"~group, data=by_HIT.table)
summary(cov_check_CQ4.1) #nothing significant
summary(cov_check_CQ4.2) #nothing significant
summary(cov_check_CQ4.3) #nothing significant
summary(cov_check_CQ4.4) #nothing significant
summary(cov_check_CQ4.5) #nothing significant
# CQ5  "Do you use Linkedin?"
# "Yes" "No" "Never heard of Linkedin"
cov_check_CQ5.1 = lm(CQ5=="Yes"~group, data=by_HIT.table)
cov_check_CQ5.2 = lm(CQ5=="No"~group, data=by_HIT.table)
cov_check_CQ5.3 = lm(CQ5=="Never heard of Linkedin"~group, data=by_HIT.table)
summary(cov_check_CQ5.1) #nothing significant
summary(cov_check_CQ5.2) #nothing significant
summary(cov_check_CQ5.3) #nothing significant
#---------------------------------------------------------------------#
# plot distribution (Brief EDA)
# specify model
lm(round_accuracy ~ group * round + CQ1 + CQ2 + CQ3 + CQ4 + CQ5,data=by_Session.table)
lm(round_accuracy ~ group * round + CQ1 + CQ2 + CQ3 + CQ4 + CQ5,data=by_Session.table)
mod.1 = lm(round_accuracy ~ group * round + CQ1 + CQ2 + CQ3 + CQ4 + CQ5,data=by_Session.table)
summary(mod.1)
rm(list = ls())
library(foreign)
library(data.table)
library(magrittr)
library(sandwich)
library(lmtest)
## Green and Gerber: Question 9.6
## a, b, and c.
## 9.6
d <- read.dta("http://hdl.handle.net/10079/vmcvdzs")
d <- data.table(d)
d
interaction <- d %>%
.[ , .(m = mean(tip)), keyby = .(female, happyface)]
interaction
m1 <- d[ , lm(tip ~ female + happyface)]
m2 <- d[ , lm(tip ~ female + happyface + female * happyface)]
anova(m2, m1, test = "F")
vcovHC(m1)
m1$rse <- vcovHC(m1)
m1$rse
m2$rse <- vcovHC(m2)
summary(m2)
stargazer(male.mod, female.mod, m2, type="text")
library(stargazer)
stargazer(male.mod, female.mod, m2, type="text")
male.mod   <- d[ female == "Male", lm(tip ~ happyface)]
female.mod <- d[ female == "Female", lm(tip ~ happyface)]
stargazer(male.mod, female.mod, m2, type="text")
group_ate
prediction_data = data.frame(female = c("Female", "Female", "Male", "Male"),
happyface = c("Happy Face", "None", "Happy Face", "None"))
prediction_data
prediction_data <- cbind(prediction_data,
predict(m2, newdata = prediction_data,
interval = "confidence", level = 0.95)
)
prediction_data
prediction_data = data.frame(female = c("Female", "Female", "Male", "Male"),
happyface = c("Happy Face", "None", "Happy Face", "None"))
prediction_data
install.packages("multcomp")
summary(glht(m2,
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
library(foreign)
library(data.table)
library(magrittr)
library(sandwich)
library(lmtest)
library(multcomp)
summary(glht(m2,
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
summary(glht(m2,
linfct=rbind(
female_vs_male_neither_happy_face=c(0,1,0,0) == 1,
male_vs_male_with_happy_face=c(0,0,1,0),
female_happy_face_vs_male_not_happy_face=c(0,1,0,1))))
summary(glht(m2,
linfct=rbind(
female_vs_male_neither_happy_face=c(0,1,0,0) ,
male_vs_male_with_happy_face=c(0,0,1,0),
female_happy_face_vs_male_not_happy_face=c(0,1,0,1))))
rm(list = ls())
# load supporting functions
# setwd("/home/fred/Field_Experiment_Human_Image_Classification/code")
setwd("F:/001_Learn_UCB/241_Experiments_and_Causality/final_project/Field_Experiment_Human_Image_Classification/code")
source(file = "design2_data_transformation_functions.r")
#source(file = "design2_data_analysis_functions.r")
#---------------------------------------------------------------------#
# read in data for analysis
by_HIT.table = fread("../modeling_data/design2_by_HIT.csv")
by_Session.table = fread("../modeling_data/design2_by_Session.csv")
View(by_HIT.table)
View(by_Session.table)
mod.1 = lm(round_accuracy ~ group * round + CQ1 + CQ2 + CQ3 + CQ4 + CQ5,data=by_Session.table)
summary(mod.1)
?glht
library(multcomp)
summary(glht(m2,
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
library(foreign)
library(data.table)
library(magrittr)
library(sandwich)
library(lmtest)
## Green and Gerber: Question 9.6
## a, b, and c.
## 9.6
d <- read.dta("http://hdl.handle.net/10079/vmcvdzs")
d <- data.table(d)
## a. SKIP
## b.
## group means?
ate <- d %>%
.[ , .(m = mean(tip)), keyby = .(happyface)] %>%
.[ , diff(m)]
ate
group_ate <- d %>%
.[ , .(m = mean(tip)), keyby = .(female, happyface)] %>%
.[ , .(ate = diff(m)), keyby = .(female)]
group_ate
interaction <- d %>%
.[ , .(m = mean(tip)), keyby = .(female, happyface)] %>%
.[ , .(ate = diff(m)), keyby = .(female)] %>%
.[ , .(diff(ate))]
interaction
## ok, the models.
m1 <- d[ , lm(tip ~ female + happyface)]
m2 <- d[ , lm(tip ~ female + happyface + female * happyface)]
## Estimate whether the interaction is significant.
## Rejecting the null hypothesis on this these /literally/
## means that the model that includes the interaction
## predicts more of the outcome, leaving smaller residuals,
## than does the short model.
anova(m2, m1, test = "F")
summary(m2)
## Great, so there does seem to be a difference between the two.
## Let's look into these differences.
m1$rse <- vcovHC(m1)
m2$rse <- vcovHC(m2)
coeftest(m2, vcovHC)                    # note that these two forms are
coeftest(m2, m2$rse)                    # equivalent.
## So, we would interpret this is meaning that the females earn tips
## that are on average 8.89 dollars higher when the leave a tip than
## when a male left a tip.
## What is the intuitive way to present these results? Well, I think
## that presenting the subset relationship is a pretty easy way to
## show this to folks.
## A few notes:
##   1. This does not have a test built in, so this is just for showing
##      people who want a sense of what is happening in the test
##   2. This test will have _uniformly_ lesser power than the model that
##      estimates the interaction. Why? If you're using any featuers that
##      have a a constant effect between the HTE feature -- e.g. age -- then
##      you're not using this information in the models. Instead, you're
##      fitting that relationship twice -- the relationship between age and Y
##      in one subset, and then the relationship beween age and Y in the other
##      subset. There is no free lunch in statistics, and the penalty to pay
##      for more flexibility (i.e. fitting twice) is a lack in precision.
male.mod   <- d[ female == "Male", lm(tip ~ happyface)]
female.mod <- d[ female == "Female", lm(tip ~ happyface)]
coeftest(male.mod, vcovHC)
summary(female.mod)
## Note that this recovers the same thing as the first group-by call
## that we made.
stargazer(male.mod, female.mod, m2, type="text")
group_ate
##
## Use the Predction Method
##
prediction_data = data.frame(female = c("Female", "Female", "Male", "Male"),
happyface = c("Happy Face", "None", "Happy Face", "None"))
prediction_data
prediction_data <- cbind(prediction_data,
predict(m2, newdata = prediction_data,
interval = "confidence", level = 0.95)
)
prediction_data
# ------------------------------------ using linear combinations of coefficient estimates ---------------- #
# By adding the coefficients together (taking their linear combinations), we can reach the same results
library(multcomp)
summary(glht(m2,
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
summary(glht(m2,
linfct=rbind(
female_vs_male_neither_happy_face=c(0,1,0,0) ,
male_vs_male_with_happy_face=c(0,0,1,0),
female_happy_face_vs_male_not_happy_face=c(0,1,0,1))))
summary(glht(m2,
linfct=rbind(
female_vs_male_neither_happy_face=c(0,1,0,0) ,
male_vs_male_with_happy_face=c(0,0,1,0),
female_happy_face_vs_male_not_happy_face=c(0,1,0,1))))
mod.0 = lm(round_accuracy ~ group * round,data=by_Session.table)
summary(mod.0)
library(multcomp)
summary(m2)
summary(mod.0)
length(mod.0$coefficients)
summary(glht(mod.0,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
female_not_happy_face=c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
summary(glht(mod.0,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
summary(glht(mod.1,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
summary(glht(mod.1,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
),covariate_average = T ))
?mcp
summary(mcp(mod.1,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
),covariate_average = T ))
summary(mcp(mod.1,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
) ))
summary(glht(mod.1, vcov=vcovHC(mod.1)
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
summary(glht(mod.1, vcov=vcovHC(mod.1),
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
summary(glht(mod.0, vcov=vcovHC(mod.0),
linfct=rbind(
male_not_happy_face=c(1,0,0,0),
female_not_happy_face=c(1,1,0,0),
male_happy_face=c(1,0,1,0),
female_happy_face=c(1,1,1,1))))
summary(mcp(mod.0, vcov=vcovHC(mod.0),
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
) ))
summary(mcp(mod.0,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2=c(1,0,0,0,0,0,0,0,0,0,0,1)
) ))
summary(glht(mod.0,
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2 =c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
summary(glht(mod.0, vcov=vcovHC(mod.0),
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2 =c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
?mcp
summary(mcp(mod.0, vcov=vcovHC(mod.0),
linfct=rbind(
trial1=c(1,0,0,0,0,0,0,0,0,0,0,0),
trial2 =c(1,0,0,0,0,0,0,0,0,0,0,1)
)))
lmod = lm(Fertility~., data=swiss)
summary(lmod)
View(swiss)
K = diag(length(coef(lmod)))[-1,]
K
rownames(K) = names(coef(lmod))[-1]
K
glht(lmod, linfct = K)
summary(lmod)
lmtest::coeftest(lmod, vcov=vcovHC(lmode))
lmtest::coeftest(lmod, vcov=vcovHC(lmod))
lmtest::coeftest(lmod, vcov=vcovHC(lmod))
glht(lmod, linfct = K, vcov=vcovHC(lmod))
summary(glht(lmod, linfct = K, vcov=vcovHC(lmod)))
glht(lmod, linfct = c("Agriculture = 0",
"Examination = 0",
"Education = 0",
"Catholic = 0",
"Infant.Mortality = 0"))
?aov
amod = aov(breaks ~ tension, data = warpbreaks)
View(warpbreaks)
warpbreaks
summary(mod.1)
